defaults:
    - override hydra/launcher: submitit_local

# environment
task: kinova_pick_cube
obs: state
episodic: false
num_envs: 256
num_eval_envs: 16
obs_buffer_size: 7
init_box_pos: [-0.3, 0.2]
box_gen_range: [0.1, 0.1]
termination_if_cube_goal_dist_less_than: 0.05
push_target_offset: [0., 0.2]
pick_target_offset: [0., 0., 0.2]
episode_length: 200 # manually set in env class files
action_scale: 0.1
obs_noise_std: 0.01
cube_randomization_ranges:
  size: [[0.04, 0.04, 0.04], [0.05, 0.05, 0.05]]
  dynamic_friction: [0.3, 0.4]
  static_friction: [0.3, 0.4]
  restitution: [0.1, 0.3]
  mass: [0.02, 0.06]

# evaluation
checkpoint: ???
eval_episodes: 256 # must be multiple of num_envs
eval_freq: 199_936 # must be a multiple of num_envs

# training
steps: 2_560_000 # should be multiple of num_envs
batch_size: 512
steps_per_update: 16 # should be a divisor of num_envs
reward_coef: 0.1
value_coef: 0.1
termination_coef: 1
consistency_coef: 20
rho: 0.5
lr: 3e-4
enc_lr_scale: 0.3
grad_clip_norm: 20
tau: 0.01
discount_denom: 5
discount_min: 0.95
discount_max: 0.995
buffer_size: 199_936 # should be multiple of num_envs
exp_name: default
data_dir: ???
cuda_device: 0

# planning
mpc: true
iterations: 6
num_samples: 512
num_elites: 64
num_pi_trajs: 24
horizon: 3
min_std: 0.05
max_std: 2
temperature: 0.5

# actor
log_std_min: -10
log_std_max: 2
entropy_coef: 1e-4

# critic
num_bins: 101
vmin: -10
vmax: +10

# architecture
use_stochastic_dynamics: false
model_size: ??? # preset config, below ignored
num_enc_layers: 2
enc_dim: 48
num_channels: 32
mlp_dim: 48
latent_dim: 32
task_dim: 96
num_q: 2
dropout: 0.01
simnorm_dim: 8

# logging
wandb_project: RL-Research
wandb_entity: vishalschool1234-university-of-waterloo
wandb_silent: false
enable_wandb: true
save_csv: false

# misc
compile: false
save_video: true
save_agent: true
seed: 1

# convenience
work_dir: ???
task_title: ???
multitask: ???
tasks: ???
obs_shape: ???
action_dim: ???
obs_shapes: ???
action_dims: ???
episode_lengths: ???
seed_steps: ???
bin_size: ???
